{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fieldmove note merger\n",
    "\n",
    "Data collected with the Fieldmove Clino app in the field can be exported into a number of discrete .csv files. The code in this notebook:\n",
    "* imports these files into pandas dataframes\n",
    "* combines these dataframes into a single dataframe\n",
    "* filters the dataframe to only include data fields that are particularly relevant\n",
    "* exports this filtered dataframe as a LaTEX table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from dateutil.parser import parse\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set your folder path here.\n",
    "\n",
    "First time users:\n",
    "* Using Terminal, navigate to the folder that contains all Fieldmove Clino .csv's\n",
    "* Enter command 'pwd'\n",
    "* Copy + paste output\n",
    "\n",
    "Everyone else:\n",
    "* Uncomment your particular path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/yuempark/Documents/Berkeley/Ethiopia/FieldMove/project1.fm\n"
     ]
    }
   ],
   "source": [
    "# folder_path = u'/Users/Laurentia/Dropbox/research_projects/keweenawan/2015_fieldwork/Field_data/Michipicoten_data/project1.fm'\n",
    "folder_path = '/Users/yuempark/Documents/Berkeley/Ethiopia/FieldMove/project1.fm'\n",
    "\n",
    "print(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.csv imported with 200 entries.\n",
      "note.csv imported with 438 entries.\n",
      "plane.csv imported with 372 entries.\n",
      "line.csv imported with 10 entries.\n"
     ]
    }
   ],
   "source": [
    "image = pd.read_csv(folder_path + '/image.csv')\n",
    "note = pd.read_csv(folder_path + '/note.csv')\n",
    "plane = pd.read_csv(folder_path + '/plane.csv')\n",
    "line = pd.read_csv(folder_path + '/line.csv')\n",
    "\n",
    "print('image.csv imported with ' + str(image.shape[0]) + ' entries.')\n",
    "print('note.csv imported with ' + str(note.shape[0]) + ' entries.')\n",
    "print('plane.csv imported with ' + str(plane.shape[0]) + ' entries.')\n",
    "print('line.csv imported with ' + str(line.shape[0]) + ' entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate the 4 data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_notes = pd.concat((image, note, plane, line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort by time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_notes['time'] = pd.to_datetime(all_notes[' timedate'])\n",
    "all_notes.sort(columns='time',inplace='True')\n",
    "all_notes.reset_index(inplace='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to all_notes.csv, without any filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', ' altitude', ' dataId', ' dip', ' dipAzimuth', ' heading',\n",
      "       ' horiz_precision', ' hozizonId', ' image name', ' latitude',\n",
      "       ' lineationType', ' longitude', ' notes', ' planeType', ' plunge',\n",
      "       ' plungeAzimuth', ' strike', ' timedate', ' vert_precision', ' x', ' y',\n",
      "       ' zone', 'localityId', 'time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "all_notes.to_csv(os.path.join(folder_path,r'all_notes.csv'))\n",
    "\n",
    "print(all_notes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns that we actually want:\n",
    "\n",
    "NOTE: it appears here that 'localityName' and 'unitId' are not headers in my .csv's... maybe this is because I only had one locality? So I will try/except."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', ' latitude', ' longitude', ' localityName', ' unitId', ' notes',\n",
      "       ' image name', ' heading', ' planeType', ' dipAzimuth', ' dip',\n",
      "       ' lineationType', ' plunge', ' plungeAzimuth', ' hozizonId'],\n",
      "      dtype='object')\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    filtered_notes = all_notes[['time',\n",
    "                                ' latitude',\n",
    "                                ' longitude',\n",
    "                                ' localityName',\n",
    "                                ' unitId',\n",
    "                                ' notes',\n",
    "                                ' image name',\n",
    "                                ' heading',\n",
    "                                ' planeType',\n",
    "                                ' dipAzimuth',\n",
    "                                ' dip',\n",
    "                                ' lineationType',\n",
    "                                ' plunge',\n",
    "                                ' plungeAzimuth',\n",
    "                                ' hozizonId']]\n",
    "    \n",
    "except:\n",
    "    fill = zeros((all_notes.shape[0],1))\n",
    "    all_notes[' localityName'] = fill\n",
    "    all_notes[' unitId'] = fill\n",
    "    filtered_notes = all_notes[['time',\n",
    "                                ' latitude',\n",
    "                                ' longitude',\n",
    "                                ' localityName',\n",
    "                                ' unitId',\n",
    "                                ' notes',\n",
    "                                ' image name',\n",
    "                                ' heading',\n",
    "                                ' planeType',\n",
    "                                ' dipAzimuth',\n",
    "                                ' dip',\n",
    "                                ' lineationType',\n",
    "                                ' plunge',\n",
    "                                ' plungeAzimuth',\n",
    "                                ' hozizonId']]\n",
    "    \n",
    "print(filtered_notes.columns)\n",
    "print(filtered_notes.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output to all_notes_filtered.csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtered_notes.to_csv(os.path.join(folder_path,r'all_notes_filtered.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert notes to a LaTeX format:\n",
    "\n",
    "The 'to_latex' package doesn't seem to handle mega-tables (like ours) well at all, so I will instead manually create a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filtered_notes_latex = filtered_notes.to_latex(longtable=True,index=False,na_rep='')\n",
    "# document = r'\\documentclass[11pt]{article}'\n",
    "# packages = r'\\usepackage{booktabs} \\usepackage{longtable}' \n",
    "# size = r'\\textwidth = 6.5 in \\textheight = 8.5 in'\n",
    "# start = r'\\begin{document}'     \n",
    "# footer = r'\\end{document}'\n",
    "# message = document + '\\n' + packages + '\\n' + size + '\\n' + start + '\\n' + filtered_notes_latex + '\\n' + footer\n",
    "# afile=open(os.path.join(folder_path,r'outputfile.tex'), 'wt')\n",
    "# afile.write(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, input the necessary frontmatter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frontmatter = r'\\documentclass[11pt]{article}' + '\\n' +\\\n",
    "              r'\\usepackage{booktabs}' + '\\n' +\\\n",
    "              r'\\usepackage{longtable}' + '\\n' +\\\n",
    "              r'\\usepackage{geometry}' + '\\n' +\\\n",
    "              r'\\geometry{hmargin={0.75in,0.75in},vmargin={1in,1in}}' + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a macro (\\nobreakhline) to make a \\hline without a page break:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "macro = r'\\makeatletter' + '\\n' +\\\n",
    "        r'\\def\\nobreakhline{' + '\\n' +\\\n",
    "        r'\\noalign{\\ifnum0=`}\\fi' + '\\n' +\\\n",
    "        r'\\penalty\\@M' + '\\n' +\\\n",
    "        r'\\futurelet\\@let@token\\LT@@nobreakhline}' + '\\n' +\\\n",
    "        r'\\def\\LT@@nobreakhline{' + '\\n' +\\\n",
    "        r'\\ifx\\@let@token\\hline' + '\\n' +\\\n",
    "        r'\\global\\let\\@gtempa\\@gobble' + '\\n' +\\\n",
    "        r'\\gdef\\LT@sep{\\penalty\\@M\\vskip\\doublerulesep}' + '\\n' +\\\n",
    "        r'\\else' + '\\n' +\\\n",
    "        r'\\global\\let\\@gtempa\\@empty' + '\\n' +\\\n",
    "        r'\\gdef\\LT@sep{\\penalty\\@M\\vskip-\\arrayrulewidth}' + '\\n' +\\\n",
    "        r'\\fi' + '\\n' +\\\n",
    "        r'\\ifnum0=`{\\fi}' + '\\n' +\\\n",
    "        r'\\multispan\\LT@cols' + '\\n' +\\\n",
    "        r'\\unskip\\leaders\\hrule\\@height\\arrayrulewidth\\hfill\\cr' + '\\n' +\\\n",
    "        r'\\noalign{\\LT@sep}' + '\\n' +\\\n",
    "        r'\\multispan\\LT@cols' + '\\n' +\\\n",
    "        r'\\unskip\\leaders\\hrule\\@height\\arrayrulewidth\\hfill\\cr' + '\\n' +\\\n",
    "        r'\\noalign{\\penalty\\@M}' + '\\n' +\\\n",
    "        r'\\@gtempa}' + '\\n' +\\\n",
    "        r'\\makeatother' + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary commands before starting the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = r'\\begin{document}' + '\\n' +\\\n",
    "        r'\\begin{longtable}{llllr}' + '\\n' +\\\n",
    "        r'\\endhead' + '\\n' +\\\n",
    "        r'\\endfoot' + '\\n' +\\\n",
    "        r'\\bottomrule' + '\\n' +\\\n",
    "        r'\\endlastfoot' + '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary commands after the table ends:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "end = r'\\end{longtable}' + '\\n' +\\\n",
    "      r'\\end{document}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the table.\n",
    "\n",
    "First, a little function to make text bold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bold(string):\n",
    "    out = r'\\textbf{' + string + '}'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "body = ''\n",
    "\n",
    "for i in range(filtered_notes.shape[0]-1):\n",
    "    entry = ''\n",
    "    entry += r'\\hline' + '\\n'\n",
    "    entry += bold('time:') + ' ' + str(filtered_notes['time'][i]) + r' & '\n",
    "    entry += bold('lat:') + ' ' + str(filtered_notes[' latitude'][i]) + r' & '\n",
    "    entry += bold('lon:') + ' ' + str(filtered_notes[' longitude'][i]) + r' & '\n",
    "    entry += r'& '\n",
    "    entry += bold('locality:') + ' ' + str(filtered_notes[' localityName'][i]) + r' \\\\' + '\\n'\n",
    "    entry += r'\\nobreakhline' + '\\n'\n",
    "    entry += r'\\multicolumn{5}{p{\\linewidth}}{'\n",
    "    entry += bold('note:') + ' ' + str(filtered_notes[' notes'][i]) + r'} \\\\' + '\\n'\n",
    "    \n",
    "    try:\n",
    "        temp = filtered_notes[' image name'][i].split('_')\n",
    "        entry += bold('image:') + ' ' + temp[0] + r'\\_' + temp[1] + r' & '\n",
    "    except:\n",
    "        entry += bold('image:') + ' ' + str(filtered_notes[' image name'][i]) + r' & '\n",
    "        \n",
    "    entry += bold('heading:') + ' ' + str(filtered_notes[' heading'][i]) + r' & '\n",
    "    entry += r'& & \\\\' + '\\n'\n",
    "    entry += bold('fm:') + ' ' + str(filtered_notes[' hozizonId'][i]) + r' & '\n",
    "    entry += r'& & & \\\\' + '\\n'\n",
    "    entry += bold('plane:') + ' ' + str(filtered_notes[' planeType'][i]) + r' & '\n",
    "    entry += bold('dip:') + ' ' + str(filtered_notes[' dip'][i]) + r' & '\n",
    "    entry += bold('azimuth:') + ' ' + str(filtered_notes[' dipAzimuth'][i]) + r' & '\n",
    "    entry += r'& \\\\' + '\\n'\n",
    "    entry += bold('line:') + ' ' + str(filtered_notes[' lineationType'][i]) + r' & '\n",
    "    entry += bold('plunge:') + ' ' + str(filtered_notes[' plunge'][i]) + r' & '\n",
    "    entry += bold('azimuth:') + ' ' + str(filtered_notes[' plungeAzimuth'][i]) + r' & '\n",
    "    entry += r'& \\\\' + '\\n'\n",
    "    entry += r'\\hline' + '\\n'\n",
    "    body += entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "body = body.replace('%','\\%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toLatex = frontmatter + macro + start + body + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491316"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afile = open(os.path.join(folder_path,r'latexoutput.tex'), 'wt')\n",
    "afile.write(toLatex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
